# 构造机器学习项目
> Coursera 专项课程 Deep Learning Specialization （由 DeepLearning.AI 提供）的第 3 课 Structuring Machine Learning Projects 的学习笔记

## 机器学习策略

正交化

1. 训练集效果良好（调整更大的网络、尝试不同的优化器）

2. 开发集效果良好（正则化、更大的训练集）

3. 测试集效果良好（更大的开发集）

4. 符合现实世界对算法的要求（更换开发集或者代价函数）

提前停止策略一般不用，因为他同时影响了训练集和开发集的效果，不完全正交

## 设置一个目标

设置一个单一的量化评估指标

Precision（精确度）：如果把一张照片分类为 A，那么有 x% 的可能它就是 A

Recall（召回率）：在所有是 A 的图片中，有 x% 可以被正确地识别出来

经常需要在这两个指标中做权衡

定义 F1 指数：可以理解为 P 和 R 的调和平均

$$\displaystyle{F_1 = \frac{2}{\frac{1}{P} + \frac{1}{R}}}$$

对于 Accuracy 和 Running time 组成的指标，我们可以把 Accuracy 看作 Optimizing、把 Running time 看作 Satisfing，即，在满足 Running time 小于给定数量的前提下，找到最大化的 Accuracy（如：Maximize Accuracy, subject to running time <= 100ms）

dev set 也常被称为 development set 或者 hold out crossove validation set

开发集和测试集要来自相同的分布

开发集和测试集的比例

什么时候改变自己的目标？当评估指标只适用于开发集和测试集的评估结果，而不符合自己或者客户的需求的时候，即当评估指标无法正确排序时。

算法 A 的错误率是 3%，算法 B 的错误率是 5%。可能出现的情况：

1. 训练集是精美的，用户上传的是不全的、模糊的，结果 B 比 A 效果好，用户更关心他们上传的图片能否被识别

2. A 可能出现色情图片，而 B 不会，用户不能忍受 A

一种可能的评估函数，可以给不同的情况设置不同的权重。

![](https://img.jxtxzzw.com/2020/10/19/qv4f6v.png)

## 人类层次

### 人类层次的表现

为什么要将机器学习系统与人类表现进行比较？

1. 在很多领域，算法和人相比更有竞争力

2. 效率更高

![](https://img.jxtxzzw.com/2020/10/19/qvihlv.png)

最终会无限接近贝叶斯最优误差，永远不会到达或者超越

贝叶斯最优误差是最小的理论误差值

超越人类级别的表现时进展会变慢？

1. 人类级别的表现与贝叶斯最优误差相差不远，超越后提升的空间太小

2. 还不如人类表现的时候，还有很多工具可以改善，而超过以后就没有这么多工具了

### 可避免误差（Avoidable Bias）

什么是表现算好，但没有过头？

基本假设：贝叶斯误差无限接近 0，人类误差是贝叶斯误差的估计值（贝叶斯误差的代理变量）

+ 若人类的误差在 1%，训练集误差在 8%，开发集误差在 10%，则该算法表现不好，应该着重优化偏差（1% -> 8%）

+ 若人类的误差在 7.5%，训练集误差在 8%，开发集误差在 10%，则可以认为该算法的表现一般，接下去是要减少方差（8% -> 10%）

贝叶斯误差与训练集误差被称为可避免误差（Avoidable Bias），决定了模型误差的下限

### 如何定义人类误差

假设对于一张 X 光影像，普通人的误差是 3%，普通医生的误差是 1%，有经验的医生的误差是 0.7%，一个团队的有经验的医生们的误差是 0.5%

+ 如果是作为贝叶斯误差的替代器：

由于人类误差是贝叶斯误差的估计值，所以取 0.5% 作为人类误差，此时贝叶斯误差应小于 0.5%。

+ 如果是为了展示一个超过普通人判断水平的系统：

可以取 1%。

### 提高模型表现

减少可避免的偏差和方差

避免偏差：

1. 训练更大的模型

2. 更长时间

3. 更优化的算法

4. NN 组织架构

5. 超参数的寻找

减少方差：

1. 更多数据

2. 正则化

3. NN 组织架构

4. 超参数的寻找

## 错误分析

狗的分类器正确率有 90%，是否需要继续优化？

可以取开发集中的错误分类的 100 张照片，看看有多少是狗，如果只有 5 张，那么即使优化了这个问题，也就只是让分类对的狗的照片多了 5 张，正确率从 90% 提高到 90.5%，如果有 50 张，那么可能就能真正地解决这个问题，达到 95% 的正确率。

### 去除分类错误的标签

一个比较推荐的做法是，在错误分析的过程中增加一列，去统计 Y 的标签错误的数量

看整体的错误率影响，如果有很重要的影响，那么去修复错误标签，如果影响不大，就不要去管了

![](/uploads/deeplearning/images/m_30b20d1e35b4d13134f3b0bff012b82c_r.png)

看哪一个影响更大，是错误的标签，还是把狗分类为猫了，还是太模糊的照片……

### 构建，并快速迭代

## 不匹配的开发和测试集

### 训练集和测试集的不同分布

有 200000 张高清训练图，10000 张用户上传的图

1. 方法 1：

	放在一起，随机洗牌，分为 205000 + 2500 + 2500

	+ 优点：来自同一分布，便于管理

	+ 巨大缺陷：开发集和测试集中大量的样本并不是目标关心的样本，而是训练数据样本（20:1）

2. 方法 2：

	所有训练图放进训练集，再放入 5000 张用户上传的图，剩下各 2500 张分别作为开发集和测试集

	+ 优点：开发集和测试集的分布相同，且是用户关心的

	+ 缺点：训练集的分布不同于开发和测试集的分布

长期以来，方法 2 的性能更好

### 不同分布上的方差和偏差分析

使用 Training-Dev Set（训练-开发子集）

将训练集随机混合，然后取出一小部分作为子集，这个这个子集和训练集就有一样的分布，而开发集和测试集也是一样的分布，训练时使用训练集（不包含训练-开发子集）。

### 人工数据合成

人工增加噪音

## 迁移学习

对于一个学习识别物体的神经网络，可以将学到的一部分知识来帮助更好地识别X摄像

例如只需要取出整个神经网络最后一层并移除这一层及其相关权重，然后为最后一层创建一个新的随机初始化的权重，使用新建的这个输出层来做诊断

如果只有小的放射数据集，可以只重新训练最后一层的权重；如果数据充分，也可以全部重新训练

迁移学习的要求：

1. Task A 和 B 有一样的输入 x

2. Task A 比起 Task B 有更多的数据

3. Task A 中低层次的特性能够用来帮助 B 的训练

## 多任务学习

迁移学习是有顺序的，先 A，再帮助 B

多任务学习是很多任务一起开始，每个任务会帮助完成其他任务

与 Softmax 的区别：可以有多个标签

多任务学习的要求：

1. 训练一组任务可以从分享低层次特性上获益

2. 对于每一个任务获得的数据的量是类似的

3. 可以训练一个足够大的神经网络来完成所有的任务

## 端对端深度学习

简单地说，我们有一些数据处理系统，或者是由多个阶段组成的学习系统——端到端的深度学习做的，它可以捕获所有的阶段，并且，通常可以将其替代为单个神经网络，也就是说运行速度更快

例：我们可以通过一张图片来分割出骨骼的信息，然后借助这个信息去分析孩子的年龄，这个多步过程会比端到端更合理，因为没有足够多的数据支撑端到端的推理

是否决定使用端到端？

优点：

1. 让数据发挥主导作用 -> 有足够的数据

2. 需要动手设计的组件变少了，不需要手工设计总监的表示形式

缺点：

1. 为了直接学习 X 到 Y 的映射，需要大量的数据

2. 失去了手工设计组件带来的潜力